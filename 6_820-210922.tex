\documentclass[class=scrartcl]{standalone}
\usepackage{chez}

\begin{document}
\section{Induction}
Recall the definition of the naturals
\[
  \texttt{N := O | S N}.
\]
To prove \(\forall n \in \texttt{N}, P(n)\) by induction,
\begin{itemize}[nosep]
  \item Prove \(P(\texttt{O})\).
  \item Assume \(P(n)\) for an arbitrary \(n \in \texttt{N}\).
        Prove \(P(\texttt{S}\, n)\).
\end{itemize}

\subsection{Structural induction}
We can extend this idea to \vocab{structural induction}:
if we have a tree datatype
\[
  \texttt{Tree := Leaf | Node Tree Tree},
\]
To prove \(\forall t \in \texttt{Tree}. P(t)\) by induction,
\begin{itemize}[nosep]
  \item Prove \(P(\texttt{Leaf})\).
  \item Assume \(P(t_1)\) and \(P(t_2)\)
        for arbitrary \(t_1, t_2 \in \texttt{Tree}\).
        Prove \(P(\texttt{Node}\, t_1\, t_2)\).
\end{itemize}

We can see another example of this if we consider the
following datatype of expressions
\[
  \texttt{E := Const N | Plus E E | Times E E}.
\]
To prove \(\forall e \in \texttt{E}. P(e)\) by induction,
\begin{itemize}[nosep]
  \item Prove \(P(\texttt{Const n})\) forall \(n \in \texttt{N}\).
  \item Assume \(P(e_1)\) and \(P(e_2)\)
        for arbitrary \(e_1, e_2 \in \texttt{E}\).
        Prove \(P(\texttt{Plus}\, e_1\, e_2)\).
  \item Assume \(P(e_1)\) and \(P(e_2)\)
        for arbitrary \(e_1, e_2 \in \texttt{E}\).
        Prove \(P(\texttt{Times}\, e_1\, e_2)\).
\end{itemize}


\subsection{Rule induction}
We can extend this even further to \vocab{rule induction}
(also called induction on the structure of derivations):

Consider proofs that a natural is even.
We know that \(0\) is even, and
we know that if \(n\) is even, then \(n+2\) is even.
\[
  \prfaxiom{\lcalcname{even}(0)}
  \qquad
  \prftree{\lcalcname{even}(n)}
          {\lcalcname{even}(n + 2)}
\]
This corresponds to the (dependent) datatype
\begin{minted}{text}
even := Even0 : even(0)
      | Even2(even(n)) : even(n + 2)
\end{minted}
To prove \(\forall n \in \texttt{N}. \texttt{even}(n) \implies P(n)\),
\begin{itemize}[nosep]
  \item Prove \(P(0)\).
  \item Assume \(P(n)\) for an arbitrary \(n \in \texttt{N}\).
        Prove \(P(n + 2)\).
\end{itemize}

Another example of this is the following structure:
\begin{minted}{text}
eval := EvConst : eval(Const n, n)
      | EvPlus eval(e1, n1) eval(e2, n2) : eval(Plus e1 e2, n1 + n2)
\end{minted}
corresponding to the inference rules:
\[
  \prfaxiom{\lcalcname{eval}(\lcalcname{Const} n, n)}
  \qquad
  \prftree{\lcalcname{eval}(e_1, n_1)}
          {\lcalcname{eval}(e_2, n_2)}
          {\lcalcname{eval}(\lcalcname{Plus} e_2\, e_2, n_1 + n_2)}
\]
To prove \(\forall e \in \texttt{E}, n \in \texttt{N}.
           \texttt{eval}(e, n) \implies P(n)\),
\begin{itemize}[nosep]
  \item Prove \(P(\lcalcname{Const} n, n)\).
  \item Assume \(P(e_1, n_1)\) and \(P(e_2, n_2)\).
        Prove \(P(\lcalcname{Plus} e_1\, e_2, n_1 + n_2)\).
\end{itemize}
One possible \(P\) we may use here is if we have some interperter,
and \(P(e, n)\) is the proposition that interpreting \(e\) gives \(n\).


\section{Type systems}
When programming, we want to know which programs are valid.
In particular, we want to determine which programs have semantics.
For instance, if
\begin{minted}{haskell}
let f x = if x then 1 else 0
 in f 6
\end{minted}
this will evaluate to \mintinline{haskell}{if 6 then 1 else 0}.
There are multiple options for how a language can handle this:
\begin{itemize}
  \item Leave the behavior up to the implementation of the language.
        (E.g.\ C, where there are things with unspecified behavior,
               like the order in which arguments are evaluated.)

        This is not a good idea.

  \item Provide a way that identifies and rules out these ``bad'' programs.
        In this case, programs will only compile/run if the programmer
        can prove they will be correct.

        This is the essence of a type system.

  \item Give every program correct behavior.
        
        This is the approach that a language like JavaScript takes:
        the \mintinline{text}{6} is typecasted into \mintinline{text}{true},
        and the program runs.
        However, this means that nonsensical things
        like adding a string to an object is defined.

        Note that \(\lambda\)-calculus also does this!

        Type systems are useful in these cases too.
\end{itemize}

\begin{adhoctheorem}{Sidenote}[Self-application]
  In \(\lambda\)-calculus, self application is essential for recursion,
  but it turns out it also introduces paradoxes.

  Consider \(u = \lambda y. \pifthenelse{(y y) = a}{b}{a}\).
  Then, \(u u = \pifthenelse{(u u) = a}{b}{a}\),
  which is a contradiction.

  This was one of the original motivation for types.
\end{adhoctheorem}

In a narrow sense, a type system is a mechanism for ensuring that
variables only take values from a certain predefined category.
However, it can also be viewed as a proof system or annotation system
that lets us check a specific property of interest for a program.
In particular, they can even deal with information flow violations,
deadlocks, and more.

We write \(e : T\) to represent
a \vocab{value} (or \vocab{object}) \(e\) of \vocab{type} \(T\).
When \(x : \tau\), then only operations that
are appropriate on \(\tau\) may be performed on \(x\).
We say that a program is \vocab{type correct} if
it never performs a wrong operation on an object.

Note that whether something is appropriate may differ by languages,
as in Python we can multiply lists by integers, but in Java we cannot.

A language is \vocab{type safe} if only type correct programs
can be written in that language.
Note that just because a language has types does not mean it has type safe:
\begin{itemize}[nosep]
  \item In Fortran, there is equivalence and parameter passing.
  \item In Pascal, there is variant records and files.
  \item In C/C++, there are pointers and type casting.
\end{itemize}
However, Java, Ada, ML, Go, Haskell, Bluespec, etc.\ are typesafe.

\paragraph{Type declaration and inference}
In modern languages, we can get all of the benefits of types without
explicitly declaring types.
A language is called \vocab{statically typed} if
type checking is done at compile time.
\begin{itemize}
  \item Languages where users must declare types:
        CLU, Pascal, Ada, C, C++, Fortran, Java
  \item Languages where type declaration are reconstructed during runtime:
        Scheme, Lisp
  \item Languages where type declaration are not required but allowed,
        and are reconstructed during runtime:
        ML, Go, Haskell, pH, Bluespec
\end{itemize}
Recently, the boundary between the languages that require
type declarations and those that don't is becoming fuzzier,
as type inference is catching on.

\paragraph{Polymorphism}
A \vocab{polymorphic language} is a language in which
there are type variables.
For instance, in Pascal, a monomorphic language,
there has to be a different length function for each type of list.
A non-polymorphic type is called a \vocab{simple type}.

In a polymorphic language like ML, there is a polymorphic type
\mintinline{sml}{list t}, where \mintinline{sml}{t} is the type variable,
and we can define a single function to determine the length.

Most modern functional programming languages have type systems,
and follow the Hindley-Milner type system.

\subsection{Formal definition}
A type system of a language is almost never orthogonal
to the semantics of a langage, as the types might affect
the behavior of the language (e.g.\ operator overloading).
When we define a typed language, we need
\begin{itemize}[nosep]
  \item the syntax,
  \item the dynamic semantics (operational semantics),
  \item the static semantics (typing rules, and how types are assigned), and
  \item a type soundness argument
        (relationship between static and dynamic semantics).
\end{itemize}

In the language, the type system assigns types to elements.
For example, \(5 : \texttt{Int}\)
and \(\texttt{"Hello"} : \texttt{String}\). % chktex 18
However, the types of some elements (like \texttt{x})
depends on the environment.
We denote this by \(\Gamma \vdash e : T\).
The \(\Gamma\) is the environment,
and we call the entire statement a \vocab{judgement}.

The typing rules tell us how to derive typing judgements.
These look very similar to the derivation rules
in big step operational semantics.

\begin{example}
  For the language of expressions, the typing judgements are
  \[
    \prftree{x : T \in \Gamma}
            {\Gamma \vdash x : T} \qquad
    \prfaxiom{\Gamma \vdash N : \pint} \qquad
    \prftree{\Gamma \vdash e_1 : \pint}
            {\Gamma \vdash e_2 : \pint}
            {\Gamma \vdash e_1 + e_2 : \pint}
  \]
  where \(x\) is a variable, and \(N\) is an integer in the language.

  If we want to prove \(x : \pint, y : \pint \vdash
                        x + (y + 5) : \pint\),
  we have the proof tree
  \[
    \prftree{\prftree{x : \pint \in \Gamma}
                     {\Gamma \vdash x : \pint}}
            {\prftree{\prftree{x : \pint \in \Gamma}
                              {\Gamma \vdash y : \pint}}
                     {\prfaxiom{\Gamma \vdash 5 : \pint}}
                     {\Gamma \vdash (y + 5) : \pint}}
            {\underbracket{x : \pint, y : \pint}_\Gamma
             \vdash x + (y + 5) : \pint}
  \]
\end{example}

\subsection{Simply typed \texorpdfstring{\(\lambda\)}{lambda}
            calculus (\texorpdfstring{\(F_1\)}{F1})}
We can introduce typing rules into lambda calculus:
\[
  \prftree{x : \tau \in \Gamma}
          {\Gamma \vdash x : \tau} \qquad
  \prftree{(\Gamma, x : \tau_1) \vdash e : \tau_2}
          {\Gamma \vdash (\lambda x: \tau_1. e) : \tau_1 \to \tau_2} \qquad
  \prftree{\Gamma \vdash e_1 : \tau' \to \tau}
          {\Gamma \vdash e_2 : \tau'}
          {\Gamma \vdash e_1 e_2 : \tau}
\]
Note that when we have a lambda, we must specify the type of the input
as we did in \(\lambda x : \tau_1. e\).

The second typing rule states that if we want to prove
a lambda \(\lambda x : \tau_1. e\) has type \(\tau_1 \to \tau_2\),
then we must show that \(e : t_2\) in the original context \(\Gamma\)
with the additional information that \(x : \tau_1\).
Note that if \(\Gamma\) has a type for \(x\) already,
then in \((\Gamma, x : \tau_1)\) it is replaced with
the new information \(x : \tau_1\).

The third typing rule states that
if \(e_1 : \tau' \to \tau\) and \(e_2 : \tau'\) in some context,
then \(e_1 e_2 : \tau\) in that context.

We also include a few more rules
\[
  \prfaxiom{\Gamma \vdash N : \pint} \qquad
  \prftree{\Gamma \vdash e_1 : \pint}
          {\Gamma \vdash e_2 : \pint}
          {\Gamma \vdash e_1 + e_2 : \pint} \qquad
  \prftree{\Gamma \vdash e_1 : \pint}
          {\Gamma \vdash e_2 : \pint}
          {\Gamma \vdash e_1 = e_2 : \pbool} \qquad
  \prftree{\Gamma \vdash e : \pbool}
          {\Gamma \vdash e_t : \tau}
          {\Gamma \vdash e_f : \tau}
          {\Gamma \vdash \pifthenelse{e}{e_t}{e_f} : \tau}
\]

\begin{example}
  If we wanted to prove
  \[
    \vdash (\lambda x: \pbool. \lambda y:\pbool. \pifthenelse{x}{y}{y+1})
             : \pbool \to \pint \to \pint,
  \]
  where nothing to the left of \(\vdash\) is the empty context,
  then we have the proof tree
  \[
    \prftree
    {\prftree
     {\prftree{\prftree{x : \pbool \in y: \pint, x : \pbool}
                       {y: \pint, x : \pbool \vdash x : \pbool}}
              {\prftree{y : \pint \in y: \pint, x : \pbool}
                       {y: \pint, x : \pbool \vdash y : \pint}}
              {\prftree{\prftree{y : \pint \in y: \pint, x : \pbool}
                                {y: \pint, x : \pbool \vdash y : \pint}}
                       {\prfaxiom{y: \pint, x : \pbool \vdash 1 : \pint}}
                       {y: \pint, x : \pbool \vdash y+1 : \pint}}
              {y: \pint, x : \pbool \vdash \pifthenelse{x}{y}{y+1} : \pint}}
     {x : \pbool \vdash
       (\lambda y: \pint.
          \pifthenelse{x}{y}{y+1})
       : \pint \to \pint}}
    {\vdash (\lambda x: \pbool.
               \lambda y: \pint.
                 \pifthenelse{x}{y}{y+1})
            : \pbool \to \pint \to \pint}
  \]
\end{example}



\end{document}
